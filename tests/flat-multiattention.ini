[main]
name="Configurations of Flat Captioning"
tf_manager=<tf_manager>
output="tests/outputs/flat-multiattention"
overwrite_output_dir=True
batch_size=1
epochs=1
train_dataset=<train_data>
val_dataset=<val_data>
trainer=<trainer>
runners=[<runner_flat_noshare_nosentinel>, <runner_flat_share_nosentinel>, <runner_flat_share_sentinel>, <runner_flat_noshare_sentinel>, <beam_runner_fss>]
postprocess=None
evaluation=[("target_flat_noshare_nosentinel", "target", <bleu>)]
logging_period=1
validation_period=20
runners_batch_size=1
test_datasets=[<val_data>]
random_seed=1234

[tf_manager]
class=tf_manager.TensorFlowManager
num_threads=4
num_sessions=1

[bleu]
class=evaluators.bleu.BLEUEvaluator

[image_reader]
class=readers.image_reader.image_reader
prefix="tests/data/flickr30k"
pad_h=224
pad_w=224
mode="RGB"

[train_data]
class=dataset.load_dataset_from_files
s_target="tests/data/flickr30k/train.en"
s_source="tests/data/flickr30k/train.en"
s_images=("tests/data/flickr30k/train_images.txt", <image_reader>)

[val_data]
class=dataset.load_dataset_from_files
s_target="tests/data/flickr30k/val.en"
s_source="tests/data/flickr30k/val.en"
s_images=("tests/data/flickr30k/val_images.txt", <image_reader>)

[imagenet]
class=encoders.imagenet_encoder.ImageNet
name="imagenet_vgg"
data_id="images"
network_type="vgg_16"
attention_layer="vgg_16/conv5/conv5_3"

[encoder]
class=encoders.sentence_encoder.SentenceEncoder
name="sentence_encoder"
rnn_size=4
max_input_len=3
embedding_size=2
dropout_keep_prob=0.5
attention_type=decoding_function.Attention
data_id="source"
vocabulary=<decoder_vocabulary>

[decoder_vocabulary]
class=vocabulary.from_dataset
datasets=[<train_data>]
series_ids=["target"]
max_size=30
overwrite=True

[flat_noshare_nosentinel]
class=encoders.encoder_wrapper.EncoderWrapper
name="wrapper"
attention_type=encoders.encoder_wrapper.FlatMultiAttention
encoders=[<encoder>, <imagenet>]
attention_state_size=5
use_sentinels=False
share_attn_projections=False

[decoder_flat_noshare_nosentinel]
class=decoders.decoder.Decoder
name="decoder_flat_noshare_nosentinel"
encoders=[<flat_noshare_nosentinel>]
rnn_size=2
embedding_size=3
use_attention=True
dropout_keep_prob=0.5
data_id="target"
max_output_len=3
vocabulary=<decoder_vocabulary>

[flat_share_nosentinel]
class=encoders.encoder_wrapper.EncoderWrapper
name="wrapper"
attention_type=encoders.encoder_wrapper.FlatMultiAttention
encoders=[<encoder>, <imagenet>]
attention_state_size=5
use_sentinels=False
share_attn_projections=True

[decoder_flat_share_nosentinel]
class=decoders.decoder.Decoder
name="decoder_flat_share_nosentinel"
encoders=[<flat_share_nosentinel>]
rnn_size=2
embedding_size=3
use_attention=True
dropout_keep_prob=0.5
data_id="target"
max_output_len=3
vocabulary=<decoder_vocabulary>

[flat_share_sentinel]
class=encoders.encoder_wrapper.EncoderWrapper
name="wrapper"
attention_type=encoders.encoder_wrapper.FlatMultiAttention
encoders=[<encoder>, <imagenet>]
attention_state_size=5
use_sentinels=True
share_attn_projections=True

[decoder_flat_share_sentinel]
class=decoders.decoder.Decoder
name="decoder_flat_share_sentinel"
encoders=[<flat_share_sentinel>]
rnn_size=2
embedding_size=3
use_attention=True
dropout_keep_prob=0.5
data_id="target"
max_output_len=3
vocabulary=<decoder_vocabulary>

[flat_noshare_sentinel]
class=encoders.encoder_wrapper.EncoderWrapper
name="wrapper"
attention_type=encoders.encoder_wrapper.FlatMultiAttention
encoders=[<encoder>, <imagenet>]
attention_state_size=5
use_sentinels=True
share_attn_projections=False

[decoder_flat_noshare_sentinel]
class=decoders.decoder.Decoder
name="decoder_flat_noshare_sentinel"
encoders=[<flat_noshare_sentinel>]
rnn_size=2
embedding_size=3
use_attention=True
dropout_keep_prob=0.5
data_id="target"
max_output_len=3
vocabulary=<decoder_vocabulary>

[beam_decoder_fss]
class=decoders.beam_search_decoder.BeamSearchDecoder
name="beam_search_decoder"
parent_decoder=<decoder_flat_share_sentinel>
beam_size=2
length_normalization=1.0

[trainer]
; This block just fills the arguments of the trainer __init__ method.
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder_flat_noshare_nosentinel>,<decoder_flat_share_nosentinel>,<decoder_flat_share_sentinel>,<decoder_flat_noshare_sentinel>]
l2_weight=1.0e-8
clip_norm=1.0

[runner_flat_noshare_nosentinel]
class=runners.runner.GreedyRunner
decoder=<decoder_flat_noshare_nosentinel>
output_series="target_flat_noshare_nosentinel"

[runner_flat_share_nosentinel]
class=runners.runner.GreedyRunner
decoder=<decoder_flat_share_nosentinel>
output_series="target_flat_share_nosentinel"

[runner_flat_share_sentinel]
class=runners.runner.GreedyRunner
decoder=<decoder_flat_share_sentinel>
output_series="target_flat_share_sentinel"

[runner_flat_noshare_sentinel]
class=runners.runner.GreedyRunner
decoder=<decoder_flat_noshare_sentinel>
output_series="target_flat_noshare_sentinel"

[beam_runner_fss]
class=runners.beamsearch_runner.BeamSearchRunner
output_series="target_fss_beam_2"
rank=2
decoder=<beam_decoder_fss>