;; Small training test

[main]
name="translation with lazy datasets and bpe"
tf_manager=<tf_manager>
output="tests/outputs/bpe"
overwrite_output_dir=True
batch_size=16
epochs=2
train_dataset=<train_data>
val_dataset=<val_data>
trainer=<trainer>
runners=[<runner>]
evaluation=[("target", evaluators.BLEU), ("target_greedy", "target", evaluators.BLEU)]
val_preview_num_examples=5
val_preview_input_series=["source", "target", "target_bpe"]
val_preview_output_series=["target_greedy"]
logging_period=20
validation_period=60
runners_batch_size=5
test_datasets=[<val_data>,<val_data_no_target>]

[tf_manager]
class=tf_manager.TensorFlowManager
num_threads=4
num_sessions=1


[train_data]
class=dataset.load
series=["source", "target", "source_bpe", "target_bpe"]
data=["tests/data/train.tc.en", "tests/data/train.tc.de", (<bpe_preprocess>, "source"), (<bpe_preprocess>, "target")]

[val_data]
class=dataset.load
series=["source", "target", "source_bpe", "target_bpe"]
data=["tests/data/val.tc.en", "tests/data/val.tc.de", (<bpe_preprocess>, "source"), (<bpe_preprocess>, "target")]

[val_data_no_target]
class=dataset.load
series=["source", "source_bpe"]
data=["tests/data/val.tc.en", (<bpe_preprocess>, "source")]

[bpe_preprocess]
class=processors.bpe.BPEPreprocessor
merge_file="tests/data/merges_100.bpe"

[bpe_postprocess]
class=processors.bpe.BPEPostprocessor

[bpe_vocabulary]
class=vocabulary.from_dataset
datasets=[<train_data>]
series_ids=["source_bpe", "target_bpe"]
max_size=209
save_file="tests/outputs/bpe_vocabulary.pickle"
overwrite=True

[encoder_input]
class=model.sequence.EmbeddedSequence
name="encoder_input"
embedding_size=11
max_length=10
data_id="source_bpe"
vocabulary=<bpe_vocabulary>

[encoder]
class=encoders.facebook_conv.SentenceEncoder
name="sentence_encoder"
dropout_keep_prob=0.5
conv_features=10
encoder_layers=2
input_sequence=<encoder_input>

[encoder_output_frozen]
class=model.gradient_blocking.StatefulView
blocked_object=<encoder>

[encoder_states_frozen]
class=model.gradient_blocking.TemporalStatefulView
blocked_object=<encoder>

[attention]
class=attention.Attention
state_size=8
name="attention_sentence_encoder"
encoder=<encoder>

[decoder]
class=decoders.decoder.Decoder
name="decoder"
encoders=[<encoder>]
embedding_size=9
attentions=[<attention>]
dropout_keep_prob=0.5
data_id="target_bpe"
max_output_len=10
vocabulary=<bpe_vocabulary>

[trainer]
; This block just fills the arguments of the trainer __init__ method.
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder>]
l2_weight=1.0e-8
clip_norm=1.0
optimizer=<adadelta>

[adadelta]
class=tf.train.AdadeltaOptimizer
name="adadelta"
learning_rate=1e-4
epsilon=1.0e-6
rho=0.95

[runner]
class=runners.GreedyRunner
decoder=<decoder>
postprocess=<bpe_postprocess>
output_series="target_greedy"
