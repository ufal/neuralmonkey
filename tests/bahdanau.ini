;; Small training test

[main]
name=translation bahdanau style
tf_manager=<tf_manager>
output=tests/tmp-test-output
overwrite_output_dir=True
batch_size=16
epochs=2
train_dataset=<train_data>
val_dataset=<val_data>
trainer=<trainer>
runners=[<runner>]
postprocess=None
evaluation=[(target, <bleu>)]
logging_period=20
validation_period=60

test_datasets=[<val_data_no_target>]

[tf_manager]
class=tf_manager.TensorFlowManager
num_threads=4
num_sessions=1

[bleu]
class=evaluators.bleu.BLEUEvaluator

[train_data]
; This is a definition of the training data object. Dataset is not a standard
; class, it treats the __init__ method's arguments as a dictionary, therefore
; the data series names can be any string, prefixed with "s_". To specify the
; output file for a series, use "s_" prefix and "_out" suffix, e.g.
; "s_target_out"
class=config.utils.dataset_from_files
s_source=tests/data/train.tc.en
s_target=tests/data/train.tc.de

[val_data]
; Validation data, the languages are not necessary here, encoders and decoders
; access the data series via the string identifiers defined here.
class=config.utils.dataset_from_files
s_source=tests/data/val.tc.en
s_target=tests/data/val.tc.de


[val_data_no_target]
; Validation data, the languages are not necessary here, encoders and decoders
; access the data series via the string identifiers defined here.
class=config.utils.dataset_from_files
s_source=tests/data/val.tc.en


[encoder_vocabulary]
class=config.utils.vocabulary_from_dataset
datasets=[<train_data>]
series_ids=[source]
max_size=60
save_file=tests/tmp-test-output/encoder_vocabulary.pickle
overwrite=True

[encoder]
class=encoders.sentence_encoder.SentenceEncoder
name=sentence_encoder
rnn_size=7
max_input_len=10
embedding_size=11
attention_type=decoding_function.Attention
data_id=source
vocabulary=<encoder_vocabulary>

[decoder_vocabulary]
class=config.utils.vocabulary_from_dataset
datasets=[<train_data>]
series_ids=[target]
max_size=70
save_file=tests/tmp-test-output/decoder_vocabulary.pickle
overwrite=True

[decoder]
class=decoders.decoder.Decoder
name=bahdanau_decoder
encoders=[<encoder>]
project_encoder_outputs=True
rnn_size=8
embedding_size=9
use_attention=True
output_projection=<dec_maxout_output>
dropout_keep_prob=0.5
data_id=target
max_output_len=10
vocabulary=<decoder_vocabulary>

[dec_maxout_output]
class=decoders.output_projection.maxout_output
maxout_size=7

[trainer]
; This block just fills the arguments of the trainer __init__ method.
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder>]
l2_weight=1.0e-8
clip_norm=1.0

[runner]
; This block is used for both validation and testing to run the model on
; a given dataset.
class=runners.runner.GreedyRunner
output_series=target
decoder=<decoder>
